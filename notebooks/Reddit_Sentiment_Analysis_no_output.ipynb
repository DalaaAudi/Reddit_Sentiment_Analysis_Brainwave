{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZpXCdhNdFu1"
   },
   "source": [
    "# ============================\n",
    "# ðŸ“Š Reddit Sentiment Analysis for ChatGPT\n",
    "# ============================\n",
    "**Srcond Project of the Data Analytics Training Program**\n",
    "*In partnership with Brainwave Matrix Solutions - 2025*\n",
    "##### Project Goal: To understand public sentiment towards ChatGPT across Reddit.\n",
    "##### Tools Used: Python, Libraries: pandas, requests, praw, nltk, matplotlib, seaborn, wordcloud, TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYHyPbpJdZfa"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 1: Import libraries & Environment Preparation\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyl2g1Jrdd2V"
   },
   "source": [
    "# 1.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6enH9VEdPOU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzAcxToGd6Ay",
    "outputId": "27d6805e-7653-4be5-827c-0420c633d67a"
   },
   "outputs": [],
   "source": [
    "!pip install praw python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drScYcaLdmWE"
   },
   "source": [
    "# 1.2 API Setup and Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e37sodwhbXJ"
   },
   "source": [
    "### - Environment Variables Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv  \n",
    "# Load the variables from the .env file\n",
    "load_dotenv()  \n",
    "\n",
    "# Retrieve Reddit API credentials from environment variables\n",
    "client_id = os.getenv(\"REDDIT_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "user_agent = os.getenv(\"REDDIT_USER_AGENT\")\n",
    "\n",
    "# Validate credentials\n",
    "if not client_id or not client_secret:\n",
    "    raise ValueError(\"âŒ Missing Reddit API credentials. Please check your .env file\")\n",
    "else:\n",
    "    print(\"âœ… Reddit API credentials loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQvn0yUOdqMF"
   },
   "source": [
    "### - Initialize Reddit instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJuXN7CJdm8u"
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RoVgnxlds-o",
    "outputId": "af16d433-646d-4133-dbc7-983c8bff7ad7"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# Disable warnings from praw library\n",
    "logging.getLogger(\"praw\").setLevel(logging.CRITICAL)\n",
    "# Test connection with simple code: get subreddit name and number of members\n",
    "sub = reddit.subreddit('technology')\n",
    "print(f\"Subreddit: {sub.display_name}, Members: {sub.subscribers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTqDIgzdpIwS"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 2: Data Collection\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1hDfewwpNyT"
   },
   "source": [
    "### - Definition of search criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdwDkQkopM1H"
   },
   "outputs": [],
   "source": [
    "subreddit_name = 'technology'  # Target subreddit\n",
    "query = 'ChatGPT'              # Search keyword\n",
    "limit_posts = 500              # Number of posts to retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7hPg499pc5j"
   },
   "source": [
    "## 2.1 Retriving Posts from Reddit (Submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xeGH71rpdsH"
   },
   "outputs": [],
   "source": [
    "# Initialize storage list\n",
    "posts_list = []\n",
    "\n",
    "# Start search and collection process\n",
    "for submission in reddit.subreddit(subreddit_name).search(query, limit=limit_posts):\n",
    "    # Extract data from each post\n",
    "    if submission.score > 10:  # Only posts with 10+ votes\n",
    "        posts_list.append({\n",
    "            'post_id': submission.id,                   # Unique post ID\n",
    "            'title': submission.title,                  # Post title\n",
    "            'selftext': submission.selftext,            # Main content/text\n",
    "            'created_utc': submission.created_utc,      # Creation time (Unix timestamp)\n",
    "            'num_comments': submission.num_comments,    # Number of comments\n",
    "            'score': submission.score,                  # Net upvotes/downvotes\n",
    "            'url': submission.url                       # Post link\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MqFkVi9opss",
    "outputId": "be9bf651-7809-4238-e72c-69128f0072dc"
   },
   "outputs": [],
   "source": [
    "# Create structured data table\n",
    "df_posts = pd.DataFrame(posts_list)\n",
    "if not df_posts.empty:\n",
    "    # Convert timestamp to readable datetime\n",
    "    df_posts['date'] = pd.to_datetime(df_posts['created_utc'], unit='s')\n",
    "\n",
    "print(\"First 5 collected posts:\")\n",
    "print(df_posts.head())  # Preview initial data\n",
    "df_posts.to_csv('processed_posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LUjZgusbvQH"
   },
   "source": [
    "## 2.2 Retriving Comments from these Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5DvgQmEl94D"
   },
   "outputs": [],
   "source": [
    "# Initialize comment storage\n",
    "comments_list = []\n",
    "import time\n",
    "\n",
    "# Loop through each collected post\n",
    "# Try the first 5 posts only to verify the code\n",
    "for idx, row in df_posts.head(5).iterrows():\n",
    "    submission = reddit.submission(id=row['post_id'])\n",
    "    submission.comments.replace_more(limit=0)\n",
    "\n",
    "    # Extract all comments in the post\n",
    "    for comment in submission.comments.list():\n",
    "        comments_list.append({\n",
    "            'post_id': row['post_id'],           # Parent post ID\n",
    "            'comment_id': comment.id,            # Unique comment ID\n",
    "            'body': comment.body,                # Comment text content\n",
    "            'created_utc': comment.created_utc,  # Timestamp (Unix format)\n",
    "            'score': comment.score               # Upvotes/downvotes\n",
    "        })\n",
    "    # Wait a while to avoid pressure\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEjoCUVbn0yA",
    "outputId": "106c6aae-1141-4cc3-b700-a28fcb89fe2f"
   },
   "outputs": [],
   "source": [
    "# Create structured data table\n",
    "if comments_list:\n",
    "    # Create DataFrame from collected comments\n",
    "    df_comments = pd.DataFrame(comments_list)\n",
    "\n",
    "    # Convert timestamp to readable format\n",
    "    df_comments['date'] = pd.to_datetime(df_comments['created_utc'], unit='s')\n",
    "    \n",
    "    # Display sample comments\n",
    "    print(\"First 5 collected comments:\")\n",
    "    print(df_comments.head())\n",
    "else:\n",
    "    # Handle no-comments scenario\n",
    "    df_comments = pd.DataFrame(columns=[\n",
    "        'post_id', 'comment_id', 'body', 'created_utc', 'score', 'date'\n",
    "    ])\n",
    "    print(\"No comments found in collected posts.\")\n",
    "\n",
    "df_comments.to_csv('processed_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUDghIcDjzyc"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 3: Data Exploration\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IvpKFw0qyJx"
   },
   "source": [
    "## 3.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5r62jQRsWF8"
   },
   "source": [
    "### - Overview of the posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TnfDMJhbiU_",
    "outputId": "67983d08-ceea-4974-ce01-0649c1b12d7e"
   },
   "outputs": [],
   "source": [
    "print(df_posts.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ui7UsuFxny_G",
    "outputId": "3feec478-46cd-449f-8fb8-a7b326113a15"
   },
   "outputs": [],
   "source": [
    "print(df_posts.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O1DHP4srlmN"
   },
   "source": [
    "### - Overview of the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfTLG_fnrXC8",
    "outputId": "94567961-6e33-4b8a-a6c7-f5d59dfc13f8"
   },
   "outputs": [],
   "source": [
    "print(df_comments.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EfGGO-RFsF4U",
    "outputId": "15aa5a33-26c0-4023-91df-edaed9ea6512"
   },
   "outputs": [],
   "source": [
    "print(df_comments.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHEjwuf_sN23"
   },
   "source": [
    "## 3.2 Sample Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5j5wZ-JvsGwj",
    "outputId": "916060a1-0e48-41c4-cec2-5719496eb98d"
   },
   "outputs": [],
   "source": [
    "print(df_posts[['title','selftext','date','score']].sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuShLlAZs0Ql",
    "outputId": "415615a9-7f21-44c6-9878-ea3e2d66b151"
   },
   "outputs": [],
   "source": [
    "print(df_comments[['body','date','score']].sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHwQnoyHtRcE"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 4: Data Cleaning (Preprocessing)\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJGpRP83txOq"
   },
   "source": [
    "## 4.1 Preparing a list of common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "try:\n",
    "    # Attempt to use stopwords if they are already installed.\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    print(\"âœ… Stopwords loaded successfully from cache\")\n",
    "    \n",
    "except LookupError:\n",
    "    print(\"âš ï¸ Stopwords not found. Downloading...\")\n",
    "    # Download using an alternative mirror (server issue solution)\n",
    "    nltk.download('stopwords', download_dir='/usr/share/nltk_data')\n",
    "    \n",
    "    # Retry after loading\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    print(\"âœ… Stopwords downloaded and loaded successfully\")\n",
    "\n",
    "# Merged with WordCloud Stop\n",
    "custom_stopwords = set(STOPWORDS).union(stop_words)\n",
    "print(f\"ðŸš€ Created custom stopwords with {len(custom_stopwords)} terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPqeViDjvdiZ"
   },
   "source": [
    "## 4.2 Definition of the advanced cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wZWDMintiAx"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # Checking for text presence\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove links\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove punctuation marks (without removing spaces)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Convert to lowercase and remove stop words\n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    tokens = [w for w in tokens if w not in stop_words and len(w) > 2]\n",
    "\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIWaWBlCwEmp"
   },
   "source": [
    "## 4.3 Cleaning app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzrLHyoNwW1J"
   },
   "outputs": [],
   "source": [
    "# 1. Application on posts\n",
    "if not df_posts.empty:\n",
    "    # Filling the empty values\n",
    "    df_posts['title'] = df_posts['title'].fillna('')\n",
    "    df_posts['selftext'] = df_posts['selftext'].fillna('')\n",
    "    # Cleaning\n",
    "    df_posts['clean_title'] = df_posts['title'].apply(clean_text)\n",
    "    df_posts['clean_selftext'] = df_posts['selftext'].apply(clean_text)\n",
    "    # Merging fields for comprehensive analysis\n",
    "    df_posts['full_text'] = df_posts['clean_title'] + \" \" + df_posts['clean_selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkjbhYEJwaJY"
   },
   "outputs": [],
   "source": [
    "# 2. Application on comments\n",
    "if not df_comments.empty:\n",
    "    df_comments['body'] = df_comments['body'].fillna('')\n",
    "    df_comments['clean_body'] = df_comments['body'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKp0sOTKtRe1"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 5: Sentiment Analysis\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1Ea3WD1x0Mw"
   },
   "source": [
    "## 5.1 Sentiment analysis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFw-nUSVx0Yv"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def analyze_sentiment(text, neutral_threshold=0.15):\n",
    "\n",
    "    try:\n",
    "        if not text or len(text.strip()) < 3:\n",
    "            return 0.0, 'Neutral'\n",
    "\n",
    "        analysis = TextBlob(text)\n",
    "        polarity = analysis.sentiment.polarity\n",
    "\n",
    "        if polarity > neutral_threshold:\n",
    "            sentiment = 'Positive'\n",
    "        elif polarity < -neutral_threshold:\n",
    "            sentiment = 'Negative'\n",
    "        else:\n",
    "            sentiment = 'Neutral'\n",
    "\n",
    "        return polarity, sentiment\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing sentiment: {str(e)}\")\n",
    "        return 0.0, 'Neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I1yDKIs0tAN"
   },
   "source": [
    "## 5.2 Analysis application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLLgiEqlzWMe"
   },
   "outputs": [],
   "source": [
    "# 1. Analysis application on posts\n",
    "if not df_posts.empty:\n",
    "    # Applying the function and creating two new columns\n",
    "    df_posts[['post_polarity', 'post_sentiment']] = df_posts['full_text'].apply(\n",
    "        lambda x: pd.Series(analyze_sentiment(x))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32AwsT_Dz3yt"
   },
   "outputs": [],
   "source": [
    "# 2. Analysis application on comments\n",
    "if not df_comments.empty:\n",
    "    df_comments[['comment_polarity', 'comment_sentiment']] = df_comments['clean_body'].apply(\n",
    "        lambda x: pd.Series(analyze_sentiment(x))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVgmnxnT0n8g"
   },
   "source": [
    "## 5.3 Preview the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4LMBJcO1Rml",
    "outputId": "34d37927-c005-4d8d-fc4b-657e9ca69d6e"
   },
   "outputs": [],
   "source": [
    "if not df_posts.empty:\n",
    "    print(df_posts[['full_text','post_polarity','post_sentiment']].sample(3))\n",
    "if not df_comments.empty:\n",
    "    print(df_comments[['clean_body','comment_polarity','comment_sentiment']].sample(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBZ0_8IF1VwP",
    "outputId": "8f10c2f5-acff-4489-ad43-d4d847df80d4"
   },
   "outputs": [],
   "source": [
    "# 1. Random samples of publications\n",
    "print(\"=\"*50)\n",
    "print(\"A random sample of sentiment analysis of posts (3 posts):\")\n",
    "print(df_posts[['title', 'full_text', 'post_polarity', 'post_sentiment']].sample(3))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7rVL_Xn1-TE",
    "outputId": "9d4b5340-d0e8-4718-e95d-2cec55ccb8c5"
   },
   "outputs": [],
   "source": [
    "# 2. Random samples for comments\n",
    "print(\"=\"*50)\n",
    "print(\"A random sample of sentiment analysis of comments (5 comments):\")\n",
    "print(df_comments[['body', 'clean_body', 'comment_polarity', 'comment_sentiment']].sample(5))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lc-gTlbItRke"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 6: Statistical Analysis\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twuMvI4b4fqq"
   },
   "source": [
    "## 6.1 Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuVkpLni2-VC",
    "outputId": "443151d5-0136-4207-ca4e-af90e9eaf34b"
   },
   "outputs": [],
   "source": [
    "# Statistical Summary of Emotions\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Statistical Summary of Emotions:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# For posts\n",
    "if not df_posts.empty:\n",
    "    post_counts = df_posts['post_sentiment'].value_counts()\n",
    "    total_posts = len(df_posts)\n",
    "\n",
    "    print(\"\\n[Posts]\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"Total Number: {total_posts}\")\n",
    "    print(f\"Average Polarity: {df_posts['post_polarity'].mean():.2f}\")\n",
    "    print(\"\\nDistribution:\")\n",
    "    for sentiment in ['Positive', 'Neutral', 'Negative']:\n",
    "        count = post_counts.get(sentiment, 0)\n",
    "        pct = count/total_posts*100\n",
    "        print(f\"  {sentiment}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# For Comments\n",
    "if not df_comments.empty:\n",
    "    comment_counts = df_comments['comment_sentiment'].value_counts()\n",
    "    total_comments = len(df_comments)\n",
    "\n",
    "    print(\"\\n[Comments]\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"Total Number: {total_comments}\")\n",
    "    print(f\"Average Polarity: {df_comments['comment_polarity'].mean():.2f}\")\n",
    "    print(\"\\nDistribution:\")\n",
    "    for sentiment in ['Positive', 'Neutral', 'Negative']:\n",
    "        count = comment_counts.get(sentiment, 0)\n",
    "        pct = count/total_comments*100\n",
    "        print(f\"  {sentiment}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvSS4ndm45fT"
   },
   "source": [
    "## 6.2 Analysis of Extreme Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtr9zH6L5ReQ"
   },
   "source": [
    "### - Most positive/negative post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOQ51LlZ5BWp",
    "outputId": "041007ad-0b47-4747-9769-2ac9b5c8d3ad"
   },
   "outputs": [],
   "source": [
    "# 1. Posts\n",
    "if not df_posts.empty:\n",
    "    # Most positive post\n",
    "    print(\"\\nMost positive posts:\")\n",
    "    most_positive_post = df_posts.loc[df_posts['post_polarity'].idxmax()]\n",
    "    print(f\"Evaluation: {most_positive_post['post_polarity']:.2f}\")\n",
    "    print(f\"Link: {most_positive_post['url']}\") \n",
    "    # Reduce the number of characters\n",
    "    print(f\"Text: {most_positive_post['full_text'][:150]}...\")  \n",
    "\n",
    "    # Most negative post\n",
    "    print(\"\\nMost negative posts:\")\n",
    "    most_negative_post = df_posts.loc[df_posts['post_polarity'].idxmin()]\n",
    "    print(f\"Evaluation: {most_negative_post['post_polarity']:.2f}\")\n",
    "    print(f\"Link: {most_negative_post['url']}\")\n",
    "    print(f\"Text: {most_negative_post['full_text'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMgE0fSi6eBo"
   },
   "source": [
    "### - Most positive/negative comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TdFsPr96Z1Q",
    "outputId": "20007d17-e911-4dbb-e6ec-bc0ac5263e4e"
   },
   "outputs": [],
   "source": [
    "# 2. Comments\n",
    "if not df_comments.empty:\n",
    "    # Most negative comment\n",
    "    print(\"\\nMost negative comments:\")\n",
    "    most_negative_comment = df_comments.loc[df_comments['comment_polarity'].idxmin()]\n",
    "    print(f\"Evaluation: {most_negative_comment['comment_polarity']:.2f}\")\n",
    "    print(f\"Text: {most_negative_comment['clean_body'][:150]}...\")\n",
    "\n",
    "    # Most positive comment\n",
    "    print(\"\\nMost positive comments:\")\n",
    "    most_positive_comment = df_comments.loc[df_comments['comment_polarity'].idxmax()]\n",
    "    print(f\"Evaluation: {most_positive_comment['comment_polarity']:.2f}\")\n",
    "    print(f\"Text: {most_positive_comment['clean_body'][:150]}...\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mf_B6HPrtRnU"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 7: Basic Data Visualization\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S0SiMyo-j1T"
   },
   "source": [
    "## 7.1 Sentiment distribution visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOrUzEtl_QBk"
   },
   "source": [
    "### - Distribution of posts (Barplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "hAw0CCU2_XpT",
    "outputId": "1412e0be-abc3-4219-e05c-6f21c5d286a2"
   },
   "outputs": [],
   "source": [
    "if not df_posts.empty:\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.countplot(data=df_posts, x='post_sentiment', order=['Positive','Neutral','Negative'], hue='post_sentiment', palette='viridis')\n",
    "    plt.title('Distribution of posts Sentiment')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig('posts_sentiment_dist.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rpqph4gZ_LXw"
   },
   "source": [
    "### - Distribution of comments (pie chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "g5ExCHaX-iTs",
    "outputId": "63df44d8-425d-4e89-f324-d986c1dbc5e7"
   },
   "outputs": [],
   "source": [
    "if not df_comments.empty:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    # Organizing the categories logically\n",
    "    sentiment_counts = df_comments['comment_sentiment'].value_counts().reindex(['Positive', 'Neutral', 'Negative'])\n",
    "\n",
    "    #Color coding according to classification\n",
    "    palette = {'Positive': '#F7CAC9', 'Neutral': '#D8BFD8', 'Negative': '#B8D8D8'}\n",
    "\n",
    "\n",
    "    # Creating the drawing with added shadows\n",
    "    plt.pie(sentiment_counts,\n",
    "            labels=sentiment_counts.index,\n",
    "            autopct=lambda p: f'{p:.1f}%\\n({int(p/100*sentiment_counts.sum())})',\n",
    "            colors=[palette[x] for x in sentiment_counts.index],\n",
    "            startangle=90,\n",
    "            wedgeprops={'edgecolor': 'w', 'linewidth': 2},\n",
    "            shadow=True)\n",
    "\n",
    "    plt.title('Distribution of comments Sentiment', fontsize=16, pad=20)\n",
    "    plt.gca().add_artist(plt.Circle((0,0), 0.7, fc='white'))  # A white circle in the middle\n",
    "    plt.savefig('comments_sentiment_dist.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWHp-kQ_-Ord"
   },
   "source": [
    "### - Comparing the distribution of sentiments between posts and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "mnpia3SK-Q7M",
    "outputId": "6039fb65-e432-4e8e-b4a6-0bbb50cacefe"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Distribution of posts Sentiment\n",
    "sns.countplot(data=df_posts, x='post_sentiment', ax=ax[0], hue='post_sentiment', palette='viridis', order=['Positive', 'Neutral', 'Negative'])\n",
    "ax[0].set_title('Sentiment Distribution in Posts', fontsize=14)\n",
    "ax[0].set_xlabel('Sentiment')\n",
    "ax[0].set_ylabel('Number of Posts')\n",
    "\n",
    "# 2. Distribution of comments Sentiment\n",
    "sns.countplot(data=df_comments, x='comment_sentiment', ax=ax[1], hue='comment_sentiment',\n",
    "              palette='coolwarm', order=['Positive', 'Neutral', 'Negative'])\n",
    "ax[1].set_title('Sentiment Distribution in Comments', fontsize=14)\n",
    "ax[1].set_xlabel('Sentiment')\n",
    "ax[1].set_ylabel('Number of Comments')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YcYExuB9wx-",
    "outputId": "85cee476-10fd-4096-c9d5-9b938f07e3a2"
   },
   "outputs": [],
   "source": [
    "# Statistical Text Distribution\n",
    "print(\"\\nDistribution of posts Sentiment:\")\n",
    "print(df_posts['post_sentiment'].value_counts())\n",
    "\n",
    "print(\"\\nDistribution of comments Sentiment\")\n",
    "print(df_comments['comment_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPiywwhvEgc2"
   },
   "source": [
    "## 7.2 The relationship between sentiment and interaction (Engagement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "v0cu3TB3FSWI",
    "outputId": "38b1c43b-5402-400a-9b9d-8cdf9e875fff"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 1. Posts\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=df_posts, x='post_sentiment', y='score', hue='post_sentiment',\n",
    "            palette='viridis', order=['Positive', 'Neutral', 'Negative'])\n",
    "plt.title('Emotions vs Votes (Posts)', fontsize=12)\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Score (log scale)')\n",
    "plt.yscale('log')\n",
    "\n",
    "# 2. Comments\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=df_comments, x='comment_sentiment', y='score', hue='comment_sentiment',\n",
    "            palette='coolwarm', order=['Positive', 'Neutral', 'Negative'])\n",
    "plt.title('Emotions vs Votes (Comments)', fontsize=12)\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_vs_engagement.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJJsn0VevK1G"
   },
   "source": [
    "### ðŸ” Data Reveals:\n",
    "- Posts thrive on positivity â˜€ï¸\n",
    "\n",
    "- Comments ignite through controversy ðŸ”¥\n",
    "\n",
    "- Neutral content drowns in silence ðŸ”‡\n",
    "\n",
    "### Scientific Insights:\n",
    "\n",
    "1.   Why Positivity Wins:\n",
    " - Positive posts drive sharing (\"See how this changed my life!\")\n",
    " - Negative content sparks empathy but rarely drives engagement\n",
    "\n",
    "\n",
    "2.   The Controversy Paradox:\n",
    "\n",
    " - High engagement comes from \"anger responses\" not agreement\n",
    " - Algorithms favor contentious content\n",
    "\n",
    "\n",
    "3.  Outliers Decoded:\n",
    "\n",
    " *   Exceptional positive posts: Innovative solutions, success stories\n",
    " *   Viral negative posts: Collective scandals, public crises\n",
    "\n",
    "\n",
    "### Strategic Recommendations:\n",
    "\"Evidence-based roadmap:\n",
    "\n",
    "\n",
    "1.   Invest 70% in hope-driven content (Build your engagement empire)\n",
    "2.   Allocate 25% to calculated controversy (But beware: controversy is a double-edged sword!\n",
    "Negative engagement burns bright but consumes its creator)\n",
    "3. Avoid neutrality except when strategically essential\n",
    "Safe content collects digital dust\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLy7ASKG9B5N"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 8: Temporal Analysis of Sentiment\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbFRxwQdHHTM"
   },
   "source": [
    "## 8.1 The Monthly Trend of Posts Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "F5GgLK63IarL",
    "outputId": "f53d1847-c93f-425d-d254-01278210d6b2"
   },
   "outputs": [],
   "source": [
    "# Create the monthly column if it does not exist.\n",
    "if 'month' not in df_posts.columns:\n",
    "    df_posts['month'] = df_posts['date'].dt.to_period('M')\n",
    "\n",
    "# Monthly average calculation\n",
    "monthly_sentiment = df_posts.groupby('month')['post_polarity'].mean()\n",
    "\n",
    "# The graph\n",
    "monthly_sentiment.plot(kind='line', marker='o', color='blue')\n",
    "plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "plt.title('Monthly trend of average post sentiment')\n",
    "plt.ylabel('Average Polarity')\n",
    "plt.xlabel('Month')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Monthly trend of average post sentiment.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9rPHsAc1mlm"
   },
   "source": [
    "### Key Findings:\n",
    "1. Launch Peak (Jan 2023):\n",
    "\n",
    "  - Record high sentiment (0.35) during product launch\n",
    "\n",
    "2. Reality Drop (May 2023):\n",
    "\n",
    "  - 85% decline as users experienced limitations\n",
    "\n",
    "3. Trust Crisis (Aug 2024 - Present):\n",
    "\n",
    "  - Historic low (-0.15) in August 2024\n",
    "\n",
    "  - Consistent negative trend since late 2024\n",
    "\n",
    "### Action Required:\n",
    "\n",
    "- Immediate forensic analysis of August 2024 events\n",
    "\n",
    "- Investigation into persistent post-Nov 2024 decline\n",
    "\n",
    "- Cross-reference with product usage metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ru3ErHzlKOEB"
   },
   "source": [
    "## 8.2 Daily Sentiment Trend (Posts + Comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "id": "CgWVSRX7KIpo",
    "outputId": "76f55f11-7deb-4b0a-b24f-d3b7bacbe499"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Data processing and aggregation\n",
    "df_posts['date_only'] = df_posts['date'].dt.date\n",
    "df_comments['date_only'] = df_comments['date'].dt.date\n",
    "\n",
    "# Daily average calculation\n",
    "daily_posts = df_posts.resample('D', on='date')['post_polarity'].mean()\n",
    "daily_comments = df_comments.resample('D', on='date')['comment_polarity'].mean()\n",
    "\n",
    "# The graph\n",
    "if not df_posts.empty:\n",
    "    plt.plot(daily_posts, marker='o', markersize=5, color='green', label='posts', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "if not df_comments.empty:\n",
    "    plt.plot(daily_comments, marker='s', markersize=4, color='orange', label='comments', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "# Add explanatory elements\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.7)\n",
    "plt.title('Time trend of daily sentiment', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Average Polarity', fontsize=12)\n",
    "plt.legend(title='Content type')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Save the result\n",
    "plt.savefig('sentiment_trend.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rIDJOh34y6m"
   },
   "source": [
    "## 8.3 The temporal trend of the comments (percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "ZRBNJJn18A0B",
    "outputId": "f7d9aeb2-e61b-4116-f30a-3d3252ad5a65"
   },
   "outputs": [],
   "source": [
    "if not df_comments.empty:\n",
    "    # A copy of the data to protect the original\n",
    "    temp_df = df_comments.copy()\n",
    "\n",
    "    # Extract the date\n",
    "    temp_df['date_only'] = temp_df['date'].dt.date\n",
    "\n",
    "    # 1. Data collection\n",
    "    sentiment_counts = temp_df.groupby(['date_only', 'comment_sentiment']).size().unstack(fill_value=0)\n",
    "\n",
    "    # 2. Calculating percentages\n",
    "    sentiment_pct = sentiment_counts.div(sentiment_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # 3. The graph\n",
    "    palette = {'Positive':'green', 'Neutral':'gray', 'Negative':'red'}\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for sentiment in ['Positive', 'Neutral', 'Negative']:\n",
    "        sns.lineplot(x=sentiment_pct.index, y=sentiment_pct[sentiment],\n",
    "                     label=sentiment, marker='o', markersize=4, color=palette[sentiment])\n",
    "\n",
    "    plt.title('Daily comment sentiment evolution (%)', fontsize=14)\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Percentage', fontsize=12)\n",
    "    plt.legend(title='Type of feelings')\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Daily_comment_sentiment_evolution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6SnMc2O8tYI"
   },
   "source": [
    "#### **Note**: The analysis is based on a sample of only the first 5 posts - the numbers may change with complete data but the general patterns remain significant.\n",
    "\n",
    "### Analytical Conclusion: Three Critical Shifts\n",
    "\n",
    "1. The April Shock:\n",
    "\n",
    " - Sharp drop in positivity (60% â†’ 40%) and surge in negativity (20% â†’ 45%) between Apr 24-26\n",
    "\n",
    " - Indicates an exceptional event that damaged user trust\n",
    "\n",
    "2. The May Silence:\n",
    "\n",
    " - Neutral sentiment peaked at 75% of interactions\n",
    "\n",
    " - Warning sign of disengagement or unexpressed disappointment\n",
    "\n",
    "3. The Fragile June Recovery:\n",
    "\n",
    " - Positivity rebounded to 50% primarily at neutral's expense\n",
    "\n",
    " - Negativity decreased only 5% - Imbalanced improvement\n",
    "\n",
    "### Action Recommendations:\n",
    "\n",
    "- ðŸ” Investigate root causes of Apr 25 shock (updates? external events?)\n",
    "\n",
    "- ðŸ“Š Study neutral sentiment surge on May 15 (lost engagement?)\n",
    "\n",
    "- ðŸ’¡ Assess sustainability of Jun 5 recovery (permanent or temporary?)\n",
    "\"Sudden data anomalies are alarms demanding attention\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl6JO-Wr9CtW"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 9: Advanced Text Analysis\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AuEh35cHF_s"
   },
   "source": [
    "## 9.1 Wordcloud by category of Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Io2YMomW9th6"
   },
   "outputs": [],
   "source": [
    "# 1. Preparing basic stop words\n",
    "custom_stopwords = set(STOPWORDS)\n",
    "custom_stopwords.update(['the', 'and', 'to', 'of', 'a', 'in', 'is', 'it', 'that', 'this', 'was',\n",
    "                         'chatgpt', 'ai', 'model', 'prompt', 'gpt'])\n",
    "\n",
    "def create_wordcloud(texts, title, sentiment_type, source):\n",
    "\n",
    "    # Checking for data availability\n",
    "    if texts.empty:\n",
    "        print(f\"No texts available for {title}\")\n",
    "        return\n",
    "\n",
    "    # Text cleaning\n",
    "    def clean_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        # Remove links, tags, etc.\n",
    "        words = text.split()\n",
    "        cleaned = [word for word in words\n",
    "                  if not word.startswith('http')\n",
    "                  and not word.startswith('@')\n",
    "                  and not word.startswith('#')\n",
    "                  and word != 'RT']\n",
    "        return \" \".join(cleaned)\n",
    "\n",
    "    # Cleaning app\n",
    "    cleaned_texts = texts.apply(clean_text)\n",
    "\n",
    "    # Text merging\n",
    "    combined_text = \" \".join(cleaned_texts)\n",
    "\n",
    "    # Color selection\n",
    "    color_map = {\n",
    "        'positive': 'Greens',\n",
    "        'negative': 'Reds',\n",
    "        'neutral': 'Oranges'\n",
    "    }\n",
    "\n",
    "    # Creating a word cloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        colormap=color_map[sentiment_type],\n",
    "        stopwords=custom_stopwords,\n",
    "        max_words=100\n",
    "    ).generate(combined_text)\n",
    "\n",
    "    # Show the chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    # Automatically save the image in the results folder.\n",
    "    filename = f\"{source}_{sentiment_type}_wordcloud.png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7m2JRO17GKOK"
   },
   "source": [
    "## 9.2 Application on data (posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jld0Vo12GlO6"
   },
   "source": [
    "### - WordCloud of Positive Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "Pd9PaDu9GKaS",
    "outputId": "c007cdc3-6cb1-4e34-a2c5-a16649cb5fea"
   },
   "outputs": [],
   "source": [
    "# Positive post words\n",
    "if not df_posts.empty:\n",
    "    positive_posts = df_posts[df_posts['post_sentiment'] == 'Positive']['full_text']\n",
    "    create_wordcloud(positive_posts,\n",
    "                    \"Top Words in Positive Posts\",\n",
    "                    'positive', 'Posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSo6KZkdG788"
   },
   "source": [
    "### -  WordCloud for Negative Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "nThl2PidG8LK",
    "outputId": "ae04627c-f185-4ad0-c3fe-41edfdccbddc"
   },
   "outputs": [],
   "source": [
    "# Words of negative posts\n",
    "if not df_posts.empty:\n",
    "    negative_posts = df_posts[df_posts['post_sentiment'] == 'Negative']['full_text']\n",
    "    create_wordcloud(negative_posts,\n",
    "                    \"Top Words in Negative Posts\",\n",
    "                    'negative', 'Posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6EIYRCvHqAR"
   },
   "source": [
    "## 9.3 Application on data (Comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ie-TMsdPH1xe"
   },
   "source": [
    "### - WordCloud of Positive Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "KlH34EWeH2JZ",
    "outputId": "e346b890-2766-4ba1-9455-5f4b1e8ff180"
   },
   "outputs": [],
   "source": [
    "# Positive comment words\n",
    "if not df_comments.empty:\n",
    "    positive_comments = df_comments[df_comments['comment_sentiment'] == 'Positive']['clean_body']\n",
    "    create_wordcloud(positive_comments,\n",
    "                    \"Top Words in Positive Comments\",\n",
    "                    'positive', 'Comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC-jplhEH2St"
   },
   "source": [
    "### - WordCloud of Negative Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "6TwROvi8H2bz",
    "outputId": "f9a41676-7fb1-4ee5-ee17-ed6c91485d58"
   },
   "outputs": [],
   "source": [
    "# Words of negative comments\n",
    "if not df_comments.empty:\n",
    "    negative_comments = df_comments[df_comments['comment_sentiment'] == 'Negative']['clean_body']\n",
    "    create_wordcloud(negative_comments,\n",
    "                    \"Top Words in Negative Comments\",\n",
    "                    'negative', 'Comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Z7S1kDX9EdG"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 10: Conclusions & Recommendations\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx9Y0XTZx2su"
   },
   "source": [
    "\n",
    "### ðŸ” Conclusions  \n",
    "\n",
    "- **Posts sentiment**: Predominantly positive (~60%) with neutral as secondary (~35%).  \n",
    "- **Comments sentiment**: Dominated by negativity (57.7%) despite post optimism.  \n",
    "- **Critical fluctuations**: Sharp sentiment shifts coincided with major updates (e.g., 20% drop in April).  \n",
    "- **Key themes**:  \n",
    "  - âœ… Praise: \"accuracy,\" \"speed,\" \"creativity\"  \n",
    "  - âŒ Criticism: \"errors,\" \"limitations,\" \"privacy concerns\"  \n",
    "\n",
    "### ðŸš€ Recommendations  \n",
    "\n",
    "1. **Feature enhancement**  \n",
    "   - Prioritize \"accuracy\" and \"speed\" improvements  \n",
    "   - Address: privacy issues, academic limitations, response errors  \n",
    "\n",
    "2. **Sentiment monitoring**  \n",
    "   - Track sentiment pre-/post-updates  \n",
    "   - Alert team for >15% fluctuations  \n",
    "\n",
    "3. **Neutral-to-positive conversion**  \n",
    "   - Launch prompts: *\"Share a creative use case you loved!\"*  \n",
    "   - Target neutrals with topic-based content (e.g., \"research tips\")  \n",
    "\n",
    "4. **Data integrity**  \n",
    "   - Expand analysis to 50+ posts  \n",
    "   - Use stratified sampling  \n",
    "\n",
    "> âš ï¸ **Methodological Note**:  \n",
    "> Analysis based on prototype sample (first 5 posts' comments).  \n",
    "> Patterns are indicative; absolute values may shift with full data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trIim_h-9F5W"
   },
   "source": [
    "---------------------------------------\n",
    "# SECTION 11: Save the Results & Outputs\n",
    "---------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Specify the project folder by going one step back from within the notebooks folder.\n",
    "project_folder = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Required memorization paths\n",
    "processed_data_path = os.path.join(project_folder, 'processed_data')\n",
    "outputs_path = os.path.join(project_folder, 'outputs')\n",
    "\n",
    "# Make sure the required folders exist; if they do not exist, they will be created.\n",
    "for path in [processed_data_path, outputs_path]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Transfer CSV files to the processed_data folder\n",
    "if os.path.exists('processed_posts.csv'):\n",
    "    shutil.move('processed_posts.csv', os.path.join(processed_data_path, 'processed_posts.csv'))\n",
    "\n",
    "if os.path.exists('processed_comments.csv'):\n",
    "    shutil.move('processed_comments.csv', os.path.join(processed_data_path, 'processed_comments.csv'))\n",
    "\n",
    "# List of images to transfer to the outputs folder\n",
    "image_files = [\n",
    "    'posts_sentiment_dist.png',\n",
    "    'comments_sentiment_dist.png',\n",
    "    'sentiment_comparison.png',\n",
    "    'sentiment_vs_engagement.png',\n",
    "    'Monthly trend of average post sentiment.png',\n",
    "    'sentiment_trend.png',\n",
    "    'Daily_comment_sentiment_evolution.png',\n",
    "     # Word clouds\n",
    "    'Posts_positive_wordcloud.png',\n",
    "    'Posts_negative_wordcloud.png',\n",
    "    'Comments_positive_wordcloud.png',\n",
    "    'Comments_negative_wordcloud.png'\n",
    "]\n",
    "\n",
    "for img in image_files:\n",
    "    if os.path.exists(img):\n",
    "        shutil.move(img, os.path.join(outputs_path, img))\n",
    "\n",
    "print(\"âœ… CSV files and images moved successfully to the main project folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPsM4lEfyTVc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ==============================================================================================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
